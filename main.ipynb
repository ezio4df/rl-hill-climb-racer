{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Android gameplay footage (Hill Climb Racing) via scrcpy → virtual cam → Python\n",
    "\n"
   ],
   "id": "8c65e303d6aea1e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Running the model",
   "id": "ab63e34b59277a6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:38:33.234415Z",
     "start_time": "2025-11-23T11:38:31.379083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from IPython.core.display_functions import clear_output\n",
    "from PIL import Image\n"
   ],
   "id": "4da49986ed2eb2ad",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:38:33.262135Z",
     "start_time": "2025-11-23T11:38:33.258307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === CONFIG ===\n",
    "ACCEL_POS = (200, 850, 240, 850, 500)  #(x1, y1, x2, y2)\n",
    "BRAKE_POS = (2115, 850, 2200, 850, 500)  #(x1, y1, x2, y2)\n",
    "VIDEO_DEVICE = '/dev/video10'\n",
    "HOLD_DURATION_MS = 10_000  # 10 seconds (long enough to cover many steps)\n",
    "TAP_DURATION_MS = 1  # 10 seconds (long enough to cover many steps)"
   ],
   "id": "50df4e086bd9f72c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "....",
   "id": "86c5e4c186a76c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:38:33.335277Z",
     "start_time": "2025-11-23T11:38:33.322571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === HELPERS ===\n",
    "def start_hold(x, y, duration_ms=HOLD_DURATION_MS):\n",
    "    \"\"\"Start a long press in background (non-blocking)\"\"\"\n",
    "    return subprocess.Popen([\n",
    "        'adb', 'shell', 'input', 'swipe',\n",
    "        str(x), str(y), str(x), str(y), str(duration_ms)\n",
    "    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "\n",
    "def stop_hold(proc):\n",
    "    \"\"\"Gracefully stop a running hold\"\"\"\n",
    "    if proc is not None:\n",
    "        proc.terminate()\n",
    "        try:\n",
    "            proc.wait(timeout=0.1)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            proc.kill()\n",
    "\n",
    "\n",
    "def get_action_from_model(frame):\n",
    "    \"\"\"\n",
    "    Replace this with your PyTorch model.\n",
    "    Must return one of: \"accel\", \"brake\", \"none\"\n",
    "    \"\"\"\n",
    "    # Placeholder: random action (replace with real inference)\n",
    "    time.sleep(0.02)  # Simulate model latency (~20ms)\n",
    "    return np.random.choice([\"accel\", \"brake\", \"none\"])\n",
    "\n",
    "\n",
    "def get_frame(cap):\n",
    "    \"\"\"Grab single frame from video device\"\"\"\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        raise RuntimeError(\"Failed to read frame\")\n",
    "    return frame\n",
    "\n",
    "\n",
    "def resize_img(frame, width=84):\n",
    "    \"\"\"Resize frame to given width, preserving aspect ratio (height auto-scaled)\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    new_w = width\n",
    "    new_h = int(h * (new_w / w))\n",
    "    resized = cv2.resize(frame, (new_w, new_h))\n",
    "    return resized\n",
    "\n",
    "\n",
    "def ocr_distance(frame):\n",
    "    \"\"\"Extract distance from frame via OCR. Return float distance in meters.\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # ADJUST THESE CROP COORDINATES TO YOUR SCREEN\n",
    "    x1, x2 = 1800, 2200\n",
    "    y1, y2 = 20, 60\n",
    "\n",
    "    # Fix bounds\n",
    "    x1 = max(0, min(x1, w))\n",
    "    x2 = max(0, min(x2, w))\n",
    "    y1 = max(0, min(y1, h))\n",
    "    y2 = max(0, min(y2, h))\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        print(\"OCR: Invalid crop region\")\n",
    "        return 0.0\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Only show if valid\n",
    "    if roi.size > 0:\n",
    "        cv2.imshow(\"OCR Region\", roi)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    # TODO: Add OCR here later\n",
    "    return 0.0"
   ],
   "id": "33ec36b99bd0577f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## stream the screen though adb",
   "id": "2b11fd8adae06de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:32:29.424696Z",
     "start_time": "2025-11-23T10:32:27.286885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Start scrcpy in background\n",
    "scrcpy_proc = subprocess.Popen([\n",
    "    'scrcpy', f'--v4l2-sink={VIDEO_DEVICE}',\n",
    "    '--no-window', '--max-size', '720', '--stay-awake'\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_DEVICE)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Cannot open {VIDEO_DEVICE}\")"
   ],
   "id": "17baba39fa20da39",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## OCR distance",
   "id": "1c18da7012842a35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test: ocr distance from screen using `easyocr`",
   "id": "f09e2b061613c742"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import easyocr\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "\n",
    "def ocr_distance(frame):\n",
    "    \"\"\"Extract distance from frame via OCR. Return float distance in meters.\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # ADJUST THESE CROP COORDINATES TO YOUR SCREEN\n",
    "    x1, y1 = 240, 24\n",
    "    x2, y2 = x1 + 70, y1 + 19\n",
    "\n",
    "    # Fix bounds\n",
    "    x1 = max(0, min(x1, w))\n",
    "    x2 = max(0, min(x2, w))\n",
    "    y1 = max(0, min(y1, h))\n",
    "    y2 = max(0, min(y2, h))\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "\n",
    "    # Preprocessing for better OCR:\n",
    "    # Preprocessing for better OCR:\n",
    "    # Preprocessing for better OCR:\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Display (for debugging in notebook)\n",
    "    display(Image.fromarray(thresh, 'L'))\n",
    "\n",
    "    # Run EasyOCR on preprocessed image\n",
    "    try:\n",
    "        result = reader.readtext(thresh, detail=0, allowlist='0123456789m')\n",
    "        if result:\n",
    "            text = result[0].strip().lower().replace('m', '')\n",
    "            if text.isdigit():\n",
    "                print(\"OCR Distance: \", text)\n",
    "                return int(text)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "# while True:\n",
    "#     clear_output()\n",
    "#\n",
    "#     # # ret, frame = cap.read()\n",
    "#     frame = get_frame(cap)\n",
    "#     # rframe = resize_img(frame)\n",
    "#     # Image.fromarray(frame)\n",
    "#     # Image.fromarray(rframe)\n",
    "#     ocr_distance(frame)\n",
    "#     # len(frame)\n",
    "#     time.sleep(50 / 1000)\n"
   ],
   "id": "d008334870228464",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=70x19>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAAATCAAAAAAIBiQcAAAAfklEQVR4Ae2T4QqAMAiENXr/Vza1GsbOISH0p0Hhpn67XYuoZTCmCGlCrlxSEzu3OHkf77A16LhDWDcWm9RgTMGNIcQDjHnW6Ez0bPacrylN2Ju5zj+b+yRIalGNctnaEcL2LGMcwBmnjLE98/Fjcm/W96b2Qym9yeJc5xeZA+UDDiMpx2d1AAAAAElFTkSuQmCC",
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAATAEYBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+ivQPgvYaPqfxMsbPWbT7XHJFN5ELxpJE0gQn94rdVChyMc7gvbNaHhvUbPw58G5Nc/4R7Q9Uvn8QGz36nZCfbGbcPgHII5Hrjk8c1qfGHwcLr4paVoPhXR7SGe60xXS2tUjgV2DzFifurnanU+grh1+GPjdksnHhjUsXrlIswkFSGC/vB1iGT1faCOenNc/qulX2h6pcaZqdtJbXlu+yWJ+qn+RBGCCOCCCMg1Tooor0D4Jf8le0L/t4/wDSeSrmm6TqWs/AJrfS9Pu76dfFBdo7WFpWC/ZQMkKCcZIGfcV6n4h/5Oh8J/8AYKk/9Buq8sj1bUofgPNexahdpdzeLd8s6zMHdvs4kyzZyTvVWye4B6iqfxt/5K9rv/bv/wCk8def0UUVYsb+80y8jvLC7ntLqPOyaCQxuuQQcMORkEj8auab4l17RrdrfS9b1KxgZy7R2t08SlsAZIUgZwAM+wok8S69NqkOqS63qT6hCmyK7a6cyovPCvnIHzNwD3PrVP7fef2d/Z32uf7D5vn/AGbzD5fmY279vTdjjPXFF9f3mp3kl5f3c93dSY3zTyGR2wABljycAAfhVeiv/9k="
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 57\u001B[39m\n\u001B[32m     55\u001B[39m ocr_distance(frame)\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# len(frame)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m50\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m/\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test: ocr using PaddleOCR",
   "id": "f54dd8c6ceab198e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:01:14.775284Z",
     "start_time": "2025-11-23T10:00:55.295509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "ocr_engine = PaddleOCR(use_angle_cls=False, lang='en')"
   ],
   "id": "cd4496650a7c8d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezio4df/projects/rl-hill-climb-racer/.venv/lib/python3.13/site-packages/paddlex/inference/pipelines/paddleocr_vl/pipeline.py:306: SyntaxWarning: invalid escape sequence '\\('\n",
      "  result_str.replace(\"\\(\", \" $ \")\n",
      "/tmp/ipykernel_62911/63081285.py:2: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.\n",
      "  ocr_engine = PaddleOCR(use_angle_cls=False, lang='en')\n",
      "which: no ccache in (/home/ezio4df/projects/rl-hill-climb-racer/.venv/bin:/home/ezio4df/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/bin:/opt/cuda/bin:/opt/cuda/nsight_compute:/opt/cuda/nsight_systems/bin:/var/lib/flatpak/exports/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl:/opt/rocm/bin)\n",
      "/home/ezio4df/projects/rl-hill-climb-racer/.venv/lib/python3.13/site-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001B[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ezio4df/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001B[0m\n",
      "\u001B[32mCreating model: ('UVDoc', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ezio4df/.paddlex/official_models/UVDoc`.\u001B[0m\n",
      "\u001B[32mCreating model: ('PP-OCRv5_server_det', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ezio4df/.paddlex/official_models/PP-OCRv5_server_det`.\u001B[0m\n",
      "\u001B[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/ezio4df/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ADD ONCE AT TOP (after imports)\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "ocr_engine = PaddleOCR(use_angle_cls=False, lang='en')\n",
    "\n",
    "\n",
    "def ocr_distance(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1 = 240, 24\n",
    "    x2, y2 = x1 + 70, y1 + 19\n",
    "\n",
    "    x1 = max(0, min(x1, w))\n",
    "    x2 = max(0, min(x2, w))\n",
    "    y1 = max(0, min(y1, h))\n",
    "    y2 = max(0, min(y2, h))\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "\n",
    "    # Correct call: .ocr(), NOT callable\n",
    "    result = ocr_engine.ocr(roi, cls=False)\n",
    "    if result and len(result[0]) > 0:\n",
    "        text = result[0][0][1][0]\n",
    "        num_str = ''.join(filter(str.isdigit, text))\n",
    "        if num_str:\n",
    "            return int(num_str)\n",
    "    return 0\n",
    "\n",
    "# while True:\n",
    "#     clear_output()\n",
    "#\n",
    "#     # # ret, frame = cap.read()\n",
    "#     frame = get_frame(cap)\n",
    "#     # rframe = resize_img(frame)\n",
    "#     # Image.fromarray(frame)\n",
    "#     # Image.fromarray(rframe)\n",
    "#     ocr_distance(frame)\n",
    "#     # len(frame)\n",
    "#     time.sleep(500 / 1000)"
   ],
   "id": "b877df3a0607848a",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62911/2964085493.py:23: DeprecationWarning: Please use `predict` instead.\n",
      "  result = ocr_engine.ocr(roi, cls=False)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PaddleOCR.predict() got an unexpected keyword argument 'cls'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 39\u001B[39m\n\u001B[32m     35\u001B[39m frame = get_frame(cap)\n\u001B[32m     36\u001B[39m \u001B[38;5;66;03m# rframe = resize_img(frame)\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[38;5;66;03m# Image.fromarray(frame)\u001B[39;00m\n\u001B[32m     38\u001B[39m \u001B[38;5;66;03m# Image.fromarray(rframe)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m \u001B[43mocr_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[38;5;66;03m# len(frame)\u001B[39;00m\n\u001B[32m     41\u001B[39m time.sleep(\u001B[32m500\u001B[39m / \u001B[32m1000\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 23\u001B[39m, in \u001B[36mocr_distance\u001B[39m\u001B[34m(frame)\u001B[39m\n\u001B[32m     20\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[32m0\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Correct call: .ocr(), NOT callable\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m result = \u001B[43mocr_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mocr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(result[\u001B[32m0\u001B[39m]) > \u001B[32m0\u001B[39m:\n\u001B[32m     25\u001B[39m     text = result[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m][\u001B[32m1\u001B[39m][\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.5-linux-x86_64-gnu/lib/python3.13/warnings.py:637\u001B[39m, in \u001B[36mdeprecated.__call__.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    634\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(arg)\n\u001B[32m    635\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m    636\u001B[39m     warn(msg, category=category, stacklevel=stacklevel + \u001B[32m1\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m637\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/projects/rl-hill-climb-racer/.venv/lib/python3.13/site-packages/paddleocr/_pipelines/ocr.py:231\u001B[39m, in \u001B[36mPaddleOCR.ocr\u001B[39m\u001B[34m(self, img, **kwargs)\u001B[39m\n\u001B[32m    229\u001B[39m \u001B[38;5;129m@deprecated\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mPlease use `predict` instead.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    230\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mocr\u001B[39m(\u001B[38;5;28mself\u001B[39m, img, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m231\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: PaddleOCR.predict() got an unexpected keyword argument 'cls'"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test: ocr using Tesseract-OCR",
   "id": "fc989cb5d3f96751"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:13:29.331366Z",
     "start_time": "2025-11-23T10:13:29.319649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ADD ONCE AT TOP (after imports)\n",
    "import pytesseract"
   ],
   "id": "a86d7914ed8d5c78",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def ocr_distance(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1 = 240, 24\n",
    "    x2, y2 = x1 + 70, y1 + 19\n",
    "\n",
    "    x1 = max(0, min(x1, w))\n",
    "    x2 = max(0, min(x2, w))\n",
    "    y1 = max(0, min(y1, h))\n",
    "    y2 = max(0, min(y2, h))\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "\n",
    "    # Preprocess for Tesseract: B&W, high contrast\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    display(Image.fromarray(thresh))\n",
    "\n",
    "    # Run Tesseract: only digits and 'm'\n",
    "    text = pytesseract.image_to_string(\n",
    "        thresh,\n",
    "        config='--psm 8 --oem 0 -c tessedit_char_whitelist=0123456789m'\n",
    "    )\n",
    "    num_str = ''.join(filter(str.isdigit, text))\n",
    "    return int(num_str) if num_str else 0\n",
    "\n",
    "\n",
    "while True:\n",
    "    clear_output()\n",
    "\n",
    "    # # ret, frame = cap.read()\n",
    "    frame = get_frame(cap)\n",
    "    # rframe = resize_img(frame)\n",
    "    # Image.fromarray(frame)\n",
    "    # Image.fromarray(rframe)\n",
    "    print(ocr_distance(frame))\n",
    "    # len(frame)\n",
    "    time.sleep(500 / 1000)\n",
    "    break"
   ],
   "id": "556216ab3ec38e20",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=70x19>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEYAAAATCAAAAAAIBiQcAAAApklEQVR4AbVRCQ6AIAwbxv9/GcdwWTs8I5IY2lFLN0qVGWtlk9Kpeu9IGLI62BLwC0pppN3u61kQU/+VxqP0HbLxQWLclM81iYKqoOr024ftC9uo3pyGEFBt0GiYy2gDh/AvVKVq3eJAkdP0FPkurjY2pGUb8O/i7MiCYL88uHUdd+zouEqySWkm2QwjhqEeQ2rGCaeBhwTo2ou9vJOfOXGaM9VtfQMF2ho21Kd7oAAAAABJRU5ErkJggg==",
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAATAEYBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APf68/8AjRrj6D8M76W2v57K+nlhhtZYHZH37wxAZfu/Ij9x6d8VJ4KsNBtdZmfS/iDqXiKc27BrS61lLtUXcvzhFGQQcDP+0R3rzDwDoPirx58PtR1S08beIIdaivTb26y6rKtuVAjYl8Bmzh3xg9ce9b/xG1CZvjToejXfirUtC0W40zfcSWuoG1VWBnIJJO0ElUXJHPA9K7jRdS8OeEvB17qTeL7vWtLhuMzahdXn25ombYoQNGCcZKnGONxPepP+FqeBv+hmsf8Aj0+2feP3PTp/rP8Apn9//ZroNE1vTvEejwatpNx9osZ93ly7GTdtYqeGAI5BHIrQorg/iz4k03wv4Vtb3VPD1prsD3qRLbXRXajFHO8bkYZAUjp/Eeaw/Df/AAjf/C9ZP+EX/sr7D/wjR3/2Z5fl+Z9pGc+Xxuxt98YrxTStM8KS/BrXNRu5LQeKIr1Us0a7KymLMOdsW7DDDSc7T39OPd/GHiTwrbfE3S/D/iPw9o06XVl5p1bUTFiBQZSE+dDxuTj5hy/T14S7+x/8KQ+JH9neR9h/4SWT7P8AZ8eX5fnW+3ZjjbjGMcYrf8BWFmnxD8K7bSBfK8CwTx4jA2SPL8zj0Y73yep3N6muo+CX/JIdC/7eP/SiSvQKKr31hZ6nZyWd/aQXdrJjfDPGJEbBBGVPBwQD+FU9N8NaDo1w1xpeiabYzshRpLW1SJiuQcEqAcZAOPYVXn8F+Fbq4luLjw1o008rl5JJLCJmdickklckk85qxqXhrQdZuFuNU0TTb6dUCLJdWqSsFyTgFgTjJJx7miPw1oMOlzaXFommpp8z75bRbVBE7ccsmME/KvJHYelWINJ021uIri30+0hnitxaxyRwqrJCDkRggZCA87elSWNhZ6ZZx2dhaQWlrHnZDBGI0XJJOFHAyST+NWK//9k="
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### test: ocr using template",
   "id": "c89ebb3014d03a84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:08:12.601112Z",
     "start_time": "2025-11-23T10:08:12.592394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load 0-9 character templates, for ocr'ing the distance from screen\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def load_chr_templates():\n",
    "    templates = {}\n",
    "    for i in range(10):\n",
    "        path = f\"assets/chr_{i}.png\"\n",
    "        if os.path.exists(path):\n",
    "            img = cv2.imread(path, cv2.IMREAD_UNCHANGED)  # loads BGRA\n",
    "            templates[str(i)] = img\n",
    "    return templates\n",
    "\n",
    "\n",
    "chr_templates = load_chr_templates()"
   ],
   "id": "b938473e06ad9dd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:09:32.283841Z",
     "start_time": "2025-11-23T10:09:32.236794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def ocr_distance(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1 = 240, 24\n",
    "    x2, y2 = x1 + 70, y1 + 19\n",
    "\n",
    "    x1 = max(0, min(x1, w))\n",
    "    x2 = max(0, min(x2, w))\n",
    "    y1 = max(0, min(y1, h))\n",
    "    y2 = max(0, min(y2, h))\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "\n",
    "    # Convert ROI to grayscale (once)\n",
    "    # roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    roi_gray = roi\n",
    "\n",
    "    display(Image.fromarray(roi_gray))\n",
    "\n",
    "    text = \"\"\n",
    "    pos = 0\n",
    "    while pos < roi_gray.shape[1]:\n",
    "        best_char = None\n",
    "        min_diff = float('inf')\n",
    "        for char, tmpl in chr_templates.items():\n",
    "            if tmpl is None:\n",
    "                continue\n",
    "            h_t, w_t = tmpl.shape[:2]\n",
    "            if pos + w_t > roi_gray.shape[1] or h_t != roi_gray.shape[0]:\n",
    "                continue\n",
    "\n",
    "            # Extract patch (no resize)\n",
    "            patch = roi_gray[:, pos:pos + w_t]\n",
    "            if patch.shape != (h_t, w_t):\n",
    "                continue\n",
    "\n",
    "            # Extract alpha (opacity) — ignore if < 1/255\n",
    "            alpha = tmpl[:, :, 3].astype(np.float32) / 255.0\n",
    "            mask = alpha > 0.01  # treat near-transparent as transparent\n",
    "\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "\n",
    "            # Template grayscale\n",
    "            tmpl_gray = cv2.cvtColor(tmpl[:, :, :3], cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "\n",
    "            # Compute absolute difference only on opaque pixels\n",
    "            diff = np.abs(patch - tmpl_gray) * mask\n",
    "            total_diff = np.sum(diff) / np.sum(mask)  # normalize by valid pixels\n",
    "\n",
    "            if total_diff < min_diff and total_diff < 30.0:  # threshold tuned\n",
    "                min_diff = total_diff\n",
    "                best_char = char\n",
    "\n",
    "        if best_char:\n",
    "            text += best_char\n",
    "            pos += chr_templates[best_char].shape[1]  # advance by digit width\n",
    "        else:\n",
    "            pos += 1  # move 1px if no match\n",
    "\n",
    "    print(text)\n",
    "    return int(text) if text.isdigit() else 0\n",
    "\n",
    "\n",
    "frame = get_frame(cap)\n",
    "ocr_distance(frame)"
   ],
   "id": "5c271081fc3017c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=70x19>"
      ],
      "image/png": "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",
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAATAEYDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDV21f8PWcF54osorm3iuIwkr+XKgZSQvHB+tVdtJBpN3rGpQWVjqD2FwUeQXEZk3AADK/u5EPOfXHHSvOp/GjolsZOr3Wq3Glxyano9npUiI8iG30aW0YyeU/yeYzEHgk4HJ257V02q6pYaB4ggsbnw7pcmiraxmXZp6mXlG5DFguAQoIx3PNY2o/2mfhpnVE1FJTqbmNNQaVpFX7I2RmT5sbt3613EV74gHj6wtEN5/YrWqFwLUGHPlOSTJtyDuCcbvwrtW7+Rj0OM8NQXNv4O1C6g0q11LUoZLWEefaG62jau87VO48MTwarbry51kiTTY4tRnSOGOytbBrPcB5jBtkjdSN/zZwdmOoqnomm6tP4YOpabd6gkdsYIJbPT2uBJKWjQ+Z+6kA4DD+AnC9fTq0FwPiR4U+2eZ9p/sy187zc79/lXe7dnnOc5qZK8bP+tRp6mYbHVwqsdC1MKzbAfs5J3ehA5A/2iNvvUW2VJpre4gkt7iFgssUmNyEgEdCR0IPB71Vv7u5/4V14lf7TPvOvzKW8xskeQDjOemQOK3NeXPjPXf8ArtF/6IjrOpTjGLaKjJtmftoqXbRXKaD6Y8e8qRLPE6n5ZIJnicfRkIP60UUAMNv5hX7RdX10FyQt1eSzqDgjIV2IBwSM+hNKIplUKup6uqgYCrqlwAB6AB8Ae1FFHM+4WQi2whAFtcXlooAXbaXcsAIAwMhGAOBxzTWtA0gle5vWnBBW4a8lMy4yABIW3AfM3AOPmPqaKKLsLELaRaNC8LfaGhkJZ4jcyFHYrtLMu7BbHG4jPvVqKERGRvMmleRtzyTzPK7HAHLMSTwAOvaiii7CxJRRRSGf/9k="
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train custom model for accurate ocr of the distance!",
   "id": "26722e7bd8e9b779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:38:39.810039Z",
     "start_time": "2025-11-23T11:38:39.802180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def save_unique_image(img: Image.Image, folder=\"assets/extracts\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Compute hash of the image\n",
    "    img_bytes = img.tobytes()\n",
    "    img_hash = hashlib.md5(img_bytes).hexdigest()\n",
    "    filepath = os.path.join(folder, f\"{img_hash}.png\")\n",
    "\n",
    "    # Save only if not exists\n",
    "    if not os.path.exists(filepath):\n",
    "        img.save(filepath)\n",
    "        return True\n",
    "    return False"
   ],
   "id": "897e448e51d25550",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:38:39.997074Z",
     "start_time": "2025-11-23T11:38:39.990265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_distance_img(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, y1 = 240, 24\n",
    "    x2, y2 = x1 + 70, y1 + 19\n",
    "\n",
    "    x1 = max(0, min(x1, w))\n",
    "    x2 = max(0, min(x2, w))\n",
    "    y1 = max(0, min(y1, h))\n",
    "    y2 = max(0, min(y2, h))\n",
    "\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return 0\n",
    "\n",
    "    # Preprocess for Tesseract: B&W, high contrast\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # display(Image.fromarray(thresh))\n",
    "    return thresh"
   ],
   "id": "10f02f3ae358ea20",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T10:33:55.993003Z",
     "start_time": "2025-11-23T10:33:53.155259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frame = get_frame(cap)\n",
    "\n",
    "# while True:\n",
    "    clear_output()\n",
    "    start_iter = time.perf_counter()\n",
    "\n",
    "    distance_img = Image.fromarray(get_distance_img(frame))\n",
    "    did_save = save_unique_image(distance_img)\n",
    "\n",
    "    display(distance_img)\n",
    "    iter_time = time.perf_counter() - start_iter\n",
    "    print(f\"\\r took: {iter_time * 1000:.1f} ms | {'saved!' if did_save else ''}\", end=\"\")\n",
    "\n"
   ],
   "id": "e9c671278c39bbb1",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m frame = \u001B[43mget_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m      4\u001B[39m     clear_output()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 32\u001B[39m, in \u001B[36mget_frame\u001B[39m\u001B[34m(cap)\u001B[39m\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_frame\u001B[39m(cap):\n\u001B[32m     31\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Grab single frame from video device\"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m     ret, frame = \u001B[43mcap\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ret:\n\u001B[32m     34\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mFailed to read frame\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T11:38:48.958524Z",
     "start_time": "2025-11-23T11:38:48.952515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_digits(roi):\n",
    "    \"\"\"\n",
    "    Split a distance ROI (e.g., '123m') into individual digit images.\n",
    "    Assumes white digits on black background (invert if needed).\n",
    "    Returns list of cropped digit images (left to right).\n",
    "    \"\"\"\n",
    "    # Ensure binary: white digits on black background\n",
    "    if len(roi.shape) == 3:\n",
    "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = roi.copy()\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)  # white text → white foreground\n",
    "\n",
    "    # Find contours (each digit is a blob)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get bounding boxes and sort left-to-right\n",
    "    digit_bboxes = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # Filter noise (optional)\n",
    "        if w > 3 and h > 5:  # min digit size\n",
    "            digit_bboxes.append((x, y, w, h))\n",
    "\n",
    "    digit_bboxes = sorted(digit_bboxes, key=lambda b: b[0])  # sort by x\n",
    "\n",
    "    # Crop digits\n",
    "    digits = []\n",
    "    for (x, y, w, h) in digit_bboxes:\n",
    "        digit = roi[y:y+h, x:x+w]\n",
    "        digits.append(digit)\n",
    "\n",
    "    return digits"
   ],
   "id": "c84e7508e790aaa7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "distance_roi = get_distance_img(frame)  # your existing ROI\n",
    "digit_images = split_digits(distance_roi)\n",
    "\n",
    "for i, digit_img in enumerate(digit_images):\n",
    "    cv2.imshow(f\"Digit {i}\", digit_img)"
   ],
   "id": "d3aed05e100e1b35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# run the model",
   "id": "aeacc40f7f44ce78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T05:18:10.561612Z",
     "start_time": "2025-11-23T05:17:44.854631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_action = None\n",
    "current_hold_proc = None\n",
    "\n",
    "timings = []\n",
    "step = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_iter = time.perf_counter()\n",
    "\n",
    "        # Get frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Run model\n",
    "        new_action = get_action_from_model(frame)\n",
    "\n",
    "        # Execute action if changed\n",
    "        if new_action != current_action:\n",
    "            if current_hold_proc is not None:\n",
    "                current_hold_proc.terminate()\n",
    "                current_hold_proc = None\n",
    "\n",
    "            if new_action == \"accel\":\n",
    "                # 1ms tap\n",
    "                subprocess.run([\n",
    "                    'adb', 'shell', 'input', 'swipe',\n",
    "                    str(ACCEL_POS[0]), str(ACCEL_POS[1]),\n",
    "                    str(ACCEL_POS[2]), str(ACCEL_POS[3]),\n",
    "                    str(TAP_DURATION_MS)\n",
    "                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "                # Long hold\n",
    "                current_hold_proc = subprocess.Popen([\n",
    "                    'adb', 'shell', 'input', 'swipe',\n",
    "                    str(ACCEL_POS[0]), str(ACCEL_POS[1]),\n",
    "                    str(ACCEL_POS[2]), str(ACCEL_POS[3]),\n",
    "                    str(HOLD_DURATION_MS)\n",
    "                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "            elif new_action == \"brake\":\n",
    "                # 1ms tap\n",
    "                subprocess.run([\n",
    "                    'adb', 'shell', 'input', 'swipe',\n",
    "                    str(BRAKE_POS[0]), str(BRAKE_POS[1]),\n",
    "                    str(BRAKE_POS[2]), str(BRAKE_POS[3]),\n",
    "                    str(TAP_DURATION_MS)\n",
    "                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "                # Long hold\n",
    "                current_hold_proc = subprocess.Popen([\n",
    "                    'adb', 'shell', 'input', 'swipe',\n",
    "                    str(BRAKE_POS[0]), str(BRAKE_POS[1]),\n",
    "                    str(BRAKE_POS[2]), str(BRAKE_POS[3]),\n",
    "                    str(HOLD_DURATION_MS)\n",
    "                ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "            current_action = new_action\n",
    "\n",
    "        # Timing\n",
    "        iter_time = time.perf_counter() - start_iter\n",
    "        timings.append(iter_time)\n",
    "        if len(timings) > 100:\n",
    "            timings = timings[-100:]\n",
    "        avg_time = sum(timings) / len(timings)\n",
    "        fps = 1.0 / avg_time if avg_time > 0 else 0\n",
    "\n",
    "        print(f\"took: {iter_time * 1000:.1f} ms | avg took: {avg_time * 1000:.1f} ms | fps: {fps:.1f}\")\n",
    "\n",
    "        step += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    if current_hold_proc is not None:\n",
    "        current_hold_proc.terminate()\n",
    "    cap.release()"
   ],
   "id": "a735f1080f849ec0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took: 143.8 ms | avg took: 143.8 ms | fps: 7.0\n",
      "took: 127.7 ms | avg took: 135.7 ms | fps: 7.4\n",
      "took: 21.3 ms | avg took: 97.6 ms | fps: 10.2\n",
      "took: 22.8 ms | avg took: 78.9 ms | fps: 12.7\n",
      "took: 60.8 ms | avg took: 75.3 ms | fps: 13.3\n",
      "took: 52.9 ms | avg took: 71.6 ms | fps: 14.0\n",
      "took: 177.2 ms | avg took: 86.6 ms | fps: 11.5\n",
      "took: 20.4 ms | avg took: 78.4 ms | fps: 12.8\n",
      "took: 128.6 ms | avg took: 83.9 ms | fps: 11.9\n",
      "took: 20.5 ms | avg took: 77.6 ms | fps: 12.9\n",
      "took: 144.6 ms | avg took: 83.7 ms | fps: 11.9\n",
      "took: 20.6 ms | avg took: 78.4 ms | fps: 12.7\n",
      "took: 20.5 ms | avg took: 74.0 ms | fps: 13.5\n",
      "took: 118.9 ms | avg took: 77.2 ms | fps: 13.0\n",
      "took: 20.4 ms | avg took: 73.4 ms | fps: 13.6\n",
      "took: 20.4 ms | avg took: 70.1 ms | fps: 14.3\n",
      "took: 114.8 ms | avg took: 72.7 ms | fps: 13.8\n",
      "took: 20.4 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 119.7 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 20.6 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 114.7 ms | avg took: 72.0 ms | fps: 13.9\n",
      "took: 125.4 ms | avg took: 74.4 ms | fps: 13.4\n",
      "took: 144.2 ms | avg took: 77.4 ms | fps: 12.9\n",
      "took: 21.9 ms | avg took: 75.1 ms | fps: 13.3\n",
      "took: 45.9 ms | avg took: 74.0 ms | fps: 13.5\n",
      "took: 173.0 ms | avg took: 77.8 ms | fps: 12.9\n",
      "took: 125.5 ms | avg took: 79.5 ms | fps: 12.6\n",
      "took: 21.3 ms | avg took: 77.5 ms | fps: 12.9\n",
      "took: 120.4 ms | avg took: 78.9 ms | fps: 12.7\n",
      "took: 20.8 ms | avg took: 77.0 ms | fps: 13.0\n",
      "took: 20.7 ms | avg took: 75.2 ms | fps: 13.3\n",
      "took: 130.4 ms | avg took: 76.9 ms | fps: 13.0\n",
      "took: 21.0 ms | avg took: 75.2 ms | fps: 13.3\n",
      "took: 21.0 ms | avg took: 73.6 ms | fps: 13.6\n",
      "took: 132.1 ms | avg took: 75.3 ms | fps: 13.3\n",
      "took: 20.9 ms | avg took: 73.8 ms | fps: 13.6\n",
      "took: 123.3 ms | avg took: 75.1 ms | fps: 13.3\n",
      "took: 158.9 ms | avg took: 77.3 ms | fps: 12.9\n",
      "took: 148.7 ms | avg took: 79.2 ms | fps: 12.6\n",
      "took: 21.1 ms | avg took: 77.7 ms | fps: 12.9\n",
      "took: 20.7 ms | avg took: 76.3 ms | fps: 13.1\n",
      "took: 120.2 ms | avg took: 77.4 ms | fps: 12.9\n",
      "took: 117.1 ms | avg took: 78.3 ms | fps: 12.8\n",
      "took: 21.2 ms | avg took: 77.0 ms | fps: 13.0\n",
      "took: 107.9 ms | avg took: 77.7 ms | fps: 12.9\n",
      "took: 21.0 ms | avg took: 76.4 ms | fps: 13.1\n",
      "took: 116.4 ms | avg took: 77.3 ms | fps: 12.9\n",
      "took: 21.2 ms | avg took: 76.1 ms | fps: 13.1\n",
      "took: 29.0 ms | avg took: 75.2 ms | fps: 13.3\n",
      "took: 147.6 ms | avg took: 76.6 ms | fps: 13.1\n",
      "took: 21.0 ms | avg took: 75.5 ms | fps: 13.2\n",
      "took: 20.7 ms | avg took: 74.5 ms | fps: 13.4\n",
      "took: 130.4 ms | avg took: 75.5 ms | fps: 13.2\n",
      "took: 21.1 ms | avg took: 74.5 ms | fps: 13.4\n",
      "took: 20.5 ms | avg took: 73.5 ms | fps: 13.6\n",
      "took: 20.8 ms | avg took: 72.6 ms | fps: 13.8\n",
      "took: 46.6 ms | avg took: 72.1 ms | fps: 13.9\n",
      "took: 57.3 ms | avg took: 71.9 ms | fps: 13.9\n",
      "took: 56.4 ms | avg took: 71.6 ms | fps: 14.0\n",
      "took: 155.4 ms | avg took: 73.0 ms | fps: 13.7\n",
      "took: 22.0 ms | avg took: 72.2 ms | fps: 13.9\n",
      "took: 20.7 ms | avg took: 71.3 ms | fps: 14.0\n",
      "took: 145.9 ms | avg took: 72.5 ms | fps: 13.8\n",
      "took: 21.3 ms | avg took: 71.7 ms | fps: 13.9\n",
      "took: 21.1 ms | avg took: 70.9 ms | fps: 14.1\n",
      "took: 20.8 ms | avg took: 70.2 ms | fps: 14.2\n",
      "took: 44.4 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 167.0 ms | avg took: 71.2 ms | fps: 14.0\n",
      "took: 20.9 ms | avg took: 70.5 ms | fps: 14.2\n",
      "took: 133.1 ms | avg took: 71.4 ms | fps: 14.0\n",
      "took: 21.2 ms | avg took: 70.7 ms | fps: 14.1\n",
      "took: 31.5 ms | avg took: 70.1 ms | fps: 14.3\n",
      "took: 150.1 ms | avg took: 71.2 ms | fps: 14.0\n",
      "took: 20.9 ms | avg took: 70.6 ms | fps: 14.2\n",
      "took: 20.7 ms | avg took: 69.9 ms | fps: 14.3\n",
      "took: 21.4 ms | avg took: 69.3 ms | fps: 14.4\n",
      "took: 128.1 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 20.7 ms | avg took: 69.4 ms | fps: 14.4\n",
      "took: 128.7 ms | avg took: 70.1 ms | fps: 14.3\n",
      "took: 20.6 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 122.9 ms | avg took: 70.2 ms | fps: 14.2\n",
      "took: 20.7 ms | avg took: 69.6 ms | fps: 14.4\n",
      "took: 130.5 ms | avg took: 70.3 ms | fps: 14.2\n",
      "took: 21.2 ms | avg took: 69.7 ms | fps: 14.3\n",
      "took: 20.9 ms | avg took: 69.2 ms | fps: 14.5\n",
      "took: 122.9 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 20.7 ms | avg took: 69.2 ms | fps: 14.4\n",
      "took: 21.0 ms | avg took: 68.7 ms | fps: 14.6\n",
      "took: 119.2 ms | avg took: 69.2 ms | fps: 14.4\n",
      "took: 20.6 ms | avg took: 68.7 ms | fps: 14.6\n",
      "took: 20.8 ms | avg took: 68.2 ms | fps: 14.7\n",
      "took: 117.3 ms | avg took: 68.7 ms | fps: 14.6\n",
      "took: 122.8 ms | avg took: 69.3 ms | fps: 14.4\n",
      "took: 137.9 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 122.7 ms | avg took: 70.6 ms | fps: 14.2\n",
      "took: 151.9 ms | avg took: 71.4 ms | fps: 14.0\n",
      "took: 21.1 ms | avg took: 70.9 ms | fps: 14.1\n",
      "took: 135.8 ms | avg took: 71.6 ms | fps: 14.0\n",
      "took: 21.1 ms | avg took: 71.0 ms | fps: 14.1\n",
      "took: 131.6 ms | avg took: 71.7 ms | fps: 14.0\n",
      "took: 140.7 ms | avg took: 71.6 ms | fps: 14.0\n",
      "took: 20.4 ms | avg took: 70.6 ms | fps: 14.2\n",
      "took: 100.5 ms | avg took: 71.3 ms | fps: 14.0\n",
      "took: 120.8 ms | avg took: 72.3 ms | fps: 13.8\n",
      "took: 20.7 ms | avg took: 71.9 ms | fps: 13.9\n",
      "took: 153.7 ms | avg took: 72.9 ms | fps: 13.7\n",
      "took: 113.3 ms | avg took: 72.3 ms | fps: 13.8\n",
      "took: 21.2 ms | avg took: 72.3 ms | fps: 13.8\n",
      "took: 127.8 ms | avg took: 72.3 ms | fps: 13.8\n",
      "took: 21.2 ms | avg took: 72.3 ms | fps: 13.8\n",
      "took: 132.1 ms | avg took: 72.2 ms | fps: 13.9\n",
      "took: 20.7 ms | avg took: 72.2 ms | fps: 13.9\n",
      "took: 39.2 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 172.3 ms | avg took: 72.9 ms | fps: 13.7\n",
      "took: 20.8 ms | avg took: 72.9 ms | fps: 13.7\n",
      "took: 20.7 ms | avg took: 72.9 ms | fps: 13.7\n",
      "took: 102.2 ms | avg took: 72.8 ms | fps: 13.7\n",
      "took: 20.8 ms | avg took: 72.8 ms | fps: 13.7\n",
      "took: 135.8 ms | avg took: 72.9 ms | fps: 13.7\n",
      "took: 120.5 ms | avg took: 73.9 ms | fps: 13.5\n",
      "took: 131.6 ms | avg took: 74.1 ms | fps: 13.5\n",
      "took: 21.0 ms | avg took: 73.1 ms | fps: 13.7\n",
      "took: 108.8 ms | avg took: 72.7 ms | fps: 13.8\n",
      "took: 20.9 ms | avg took: 72.7 ms | fps: 13.8\n",
      "took: 110.5 ms | avg took: 73.3 ms | fps: 13.6\n",
      "took: 21.6 ms | avg took: 71.8 ms | fps: 13.9\n",
      "took: 20.8 ms | avg took: 70.8 ms | fps: 14.1\n",
      "took: 20.9 ms | avg took: 70.8 ms | fps: 14.1\n",
      "took: 132.9 ms | avg took: 70.9 ms | fps: 14.1\n",
      "took: 108.7 ms | avg took: 71.8 ms | fps: 13.9\n",
      "took: 21.6 ms | avg took: 71.8 ms | fps: 13.9\n",
      "took: 21.2 ms | avg took: 70.7 ms | fps: 14.1\n",
      "took: 61.5 ms | avg took: 71.1 ms | fps: 14.1\n",
      "took: 149.4 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 20.7 ms | avg took: 71.3 ms | fps: 14.0\n",
      "took: 126.8 ms | avg took: 72.3 ms | fps: 13.8\n",
      "took: 20.9 ms | avg took: 71.3 ms | fps: 14.0\n",
      "took: 133.6 ms | avg took: 71.1 ms | fps: 14.1\n",
      "took: 21.2 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 20.7 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 27.1 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 183.7 ms | avg took: 70.5 ms | fps: 14.2\n",
      "took: 20.9 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 130.8 ms | avg took: 70.6 ms | fps: 14.2\n",
      "took: 20.9 ms | avg took: 69.7 ms | fps: 14.3\n",
      "took: 33.4 ms | avg took: 69.9 ms | fps: 14.3\n",
      "took: 159.7 ms | avg took: 70.3 ms | fps: 14.2\n",
      "took: 21.5 ms | avg took: 70.3 ms | fps: 14.2\n",
      "took: 128.9 ms | avg took: 71.3 ms | fps: 14.0\n",
      "took: 21.6 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 176.2 ms | avg took: 71.6 ms | fps: 14.0\n",
      "took: 117.3 ms | avg took: 72.6 ms | fps: 13.8\n",
      "took: 113.6 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 20.7 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 20.5 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 21.0 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 172.1 ms | avg took: 73.7 ms | fps: 13.6\n",
      "took: 112.8 ms | avg took: 74.2 ms | fps: 13.5\n",
      "took: 20.7 ms | avg took: 73.8 ms | fps: 13.5\n",
      "took: 20.5 ms | avg took: 72.5 ms | fps: 13.8\n",
      "took: 43.6 ms | avg took: 72.7 ms | fps: 13.8\n",
      "took: 150.2 ms | avg took: 74.0 ms | fps: 13.5\n",
      "took: 131.4 ms | avg took: 73.9 ms | fps: 13.5\n",
      "took: 125.4 ms | avg took: 74.9 ms | fps: 13.3\n",
      "took: 21.3 ms | avg took: 74.9 ms | fps: 13.3\n",
      "took: 47.9 ms | avg took: 75.2 ms | fps: 13.3\n",
      "took: 151.4 ms | avg took: 76.3 ms | fps: 13.1\n",
      "took: 116.9 ms | avg took: 75.7 ms | fps: 13.2\n",
      "took: 20.9 ms | avg took: 75.7 ms | fps: 13.2\n",
      "took: 30.6 ms | avg took: 74.7 ms | fps: 13.4\n",
      "took: 48.3 ms | avg took: 75.0 ms | fps: 13.3\n",
      "took: 61.0 ms | avg took: 75.3 ms | fps: 13.3\n",
      "took: 144.4 ms | avg took: 75.2 ms | fps: 13.3\n",
      "took: 112.5 ms | avg took: 76.1 ms | fps: 13.1\n",
      "took: 20.9 ms | avg took: 76.2 ms | fps: 13.1\n",
      "took: 41.8 ms | avg took: 76.4 ms | fps: 13.1\n",
      "took: 156.7 ms | avg took: 76.6 ms | fps: 13.0\n",
      "took: 21.0 ms | avg took: 76.6 ms | fps: 13.0\n",
      "took: 20.8 ms | avg took: 75.6 ms | fps: 13.2\n",
      "took: 21.1 ms | avg took: 75.6 ms | fps: 13.2\n",
      "took: 160.4 ms | avg took: 75.9 ms | fps: 13.2\n",
      "took: 20.9 ms | avg took: 75.9 ms | fps: 13.2\n",
      "took: 138.2 ms | avg took: 76.0 ms | fps: 13.2\n",
      "took: 21.8 ms | avg took: 76.0 ms | fps: 13.2\n",
      "took: 139.1 ms | avg took: 77.2 ms | fps: 13.0\n",
      "took: 21.4 ms | avg took: 76.2 ms | fps: 13.1\n",
      "took: 135.2 ms | avg took: 77.3 ms | fps: 12.9\n",
      "took: 137.3 ms | avg took: 78.5 ms | fps: 12.7\n",
      "took: 21.3 ms | avg took: 77.5 ms | fps: 12.9\n",
      "took: 21.0 ms | avg took: 77.5 ms | fps: 12.9\n",
      "took: 20.9 ms | avg took: 77.5 ms | fps: 12.9\n",
      "took: 21.1 ms | avg took: 76.6 ms | fps: 13.1\n",
      "took: 38.8 ms | avg took: 75.7 ms | fps: 13.2\n",
      "took: 149.0 ms | avg took: 75.8 ms | fps: 13.2\n",
      "took: 21.0 ms | avg took: 74.8 ms | fps: 13.4\n",
      "took: 135.7 ms | avg took: 74.7 ms | fps: 13.4\n",
      "took: 21.2 ms | avg took: 74.7 ms | fps: 13.4\n",
      "took: 44.6 ms | avg took: 73.7 ms | fps: 13.6\n",
      "took: 192.0 ms | avg took: 75.5 ms | fps: 13.3\n",
      "took: 21.0 ms | avg took: 74.3 ms | fps: 13.5\n",
      "took: 21.1 ms | avg took: 73.2 ms | fps: 13.7\n",
      "took: 121.2 ms | avg took: 74.2 ms | fps: 13.5\n",
      "took: 20.8 ms | avg took: 73.4 ms | fps: 13.6\n",
      "took: 129.7 ms | avg took: 73.5 ms | fps: 13.6\n",
      "took: 21.0 ms | avg took: 73.5 ms | fps: 13.6\n",
      "took: 153.7 ms | avg took: 73.5 ms | fps: 13.6\n",
      "took: 21.2 ms | avg took: 72.5 ms | fps: 13.8\n",
      "took: 20.8 ms | avg took: 72.5 ms | fps: 13.8\n",
      "took: 20.7 ms | avg took: 71.5 ms | fps: 14.0\n",
      "took: 133.3 ms | avg took: 72.6 ms | fps: 13.8\n",
      "took: 146.6 ms | avg took: 72.7 ms | fps: 13.8\n",
      "took: 21.0 ms | avg took: 72.7 ms | fps: 13.8\n",
      "took: 157.2 ms | avg took: 73.9 ms | fps: 13.5\n",
      "took: 21.0 ms | avg took: 72.4 ms | fps: 13.8\n",
      "took: 121.4 ms | avg took: 73.4 ms | fps: 13.6\n",
      "took: 121.8 ms | avg took: 74.4 ms | fps: 13.4\n",
      "took: 21.6 ms | avg took: 73.6 ms | fps: 13.6\n",
      "took: 20.7 ms | avg took: 73.6 ms | fps: 13.6\n",
      "took: 110.5 ms | avg took: 73.4 ms | fps: 13.6\n",
      "took: 115.1 ms | avg took: 73.3 ms | fps: 13.6\n",
      "took: 20.7 ms | avg took: 72.2 ms | fps: 13.9\n",
      "took: 20.7 ms | avg took: 72.2 ms | fps: 13.9\n",
      "took: 48.3 ms | avg took: 71.6 ms | fps: 14.0\n",
      "took: 147.7 ms | avg took: 72.8 ms | fps: 13.7\n",
      "took: 21.2 ms | avg took: 72.0 ms | fps: 13.9\n",
      "took: 20.6 ms | avg took: 71.9 ms | fps: 13.9\n",
      "took: 133.5 ms | avg took: 73.1 ms | fps: 13.7\n",
      "took: 116.1 ms | avg took: 74.0 ms | fps: 13.5\n",
      "took: 122.7 ms | avg took: 73.9 ms | fps: 13.5\n",
      "took: 21.2 ms | avg took: 73.0 ms | fps: 13.7\n",
      "took: 20.7 ms | avg took: 73.0 ms | fps: 13.7\n",
      "took: 106.1 ms | avg took: 73.9 ms | fps: 13.5\n",
      "took: 20.7 ms | avg took: 73.5 ms | fps: 13.6\n",
      "took: 20.7 ms | avg took: 72.2 ms | fps: 13.9\n",
      "took: 106.9 ms | avg took: 73.1 ms | fps: 13.7\n",
      "took: 103.7 ms | avg took: 72.8 ms | fps: 13.7\n",
      "took: 114.6 ms | avg took: 73.8 ms | fps: 13.6\n",
      "took: 20.7 ms | avg took: 72.6 ms | fps: 13.8\n",
      "took: 20.7 ms | avg took: 72.6 ms | fps: 13.8\n",
      "took: 20.8 ms | avg took: 72.6 ms | fps: 13.8\n",
      "took: 123.6 ms | avg took: 73.6 ms | fps: 13.6\n",
      "took: 20.8 ms | avg took: 72.0 ms | fps: 13.9\n",
      "took: 20.7 ms | avg took: 72.0 ms | fps: 13.9\n",
      "took: 127.4 ms | avg took: 71.9 ms | fps: 13.9\n",
      "took: 20.8 ms | avg took: 71.9 ms | fps: 13.9\n",
      "took: 20.7 ms | avg took: 71.8 ms | fps: 13.9\n",
      "took: 117.2 ms | avg took: 71.4 ms | fps: 14.0\n",
      "took: 21.1 ms | avg took: 71.4 ms | fps: 14.0\n",
      "took: 21.2 ms | avg took: 70.3 ms | fps: 14.2\n",
      "took: 126.7 ms | avg took: 71.3 ms | fps: 14.0\n",
      "took: 109.3 ms | avg took: 70.7 ms | fps: 14.1\n",
      "took: 118.2 ms | avg took: 70.7 ms | fps: 14.1\n",
      "took: 20.9 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 120.0 ms | avg took: 70.7 ms | fps: 14.1\n",
      "took: 21.8 ms | avg took: 70.8 ms | fps: 14.1\n",
      "took: 23.3 ms | avg took: 70.8 ms | fps: 14.1\n",
      "took: 160.3 ms | avg took: 70.7 ms | fps: 14.2\n",
      "took: 20.7 ms | avg took: 69.7 ms | fps: 14.3\n",
      "took: 20.5 ms | avg took: 69.7 ms | fps: 14.3\n",
      "took: 144.3 ms | avg took: 71.0 ms | fps: 14.1\n",
      "took: 112.7 ms | avg took: 71.7 ms | fps: 14.0\n",
      "took: 21.1 ms | avg took: 70.4 ms | fps: 14.2\n",
      "took: 41.3 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 55.7 ms | avg took: 68.8 ms | fps: 14.5\n",
      "took: 51.5 ms | avg took: 69.1 ms | fps: 14.5\n",
      "took: 59.4 ms | avg took: 69.2 ms | fps: 14.5\n",
      "took: 53.7 ms | avg took: 68.2 ms | fps: 14.7\n",
      "took: 153.4 ms | avg took: 68.6 ms | fps: 14.6\n",
      "took: 21.3 ms | avg took: 68.6 ms | fps: 14.6\n",
      "took: 148.6 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 124.1 ms | avg took: 70.5 ms | fps: 14.2\n",
      "took: 114.4 ms | avg took: 71.1 ms | fps: 14.1\n",
      "took: 119.0 ms | avg took: 70.8 ms | fps: 14.1\n",
      "took: 21.7 ms | avg took: 69.9 ms | fps: 14.3\n",
      "took: 55.9 ms | avg took: 70.2 ms | fps: 14.2\n",
      "took: 156.6 ms | avg took: 71.4 ms | fps: 14.0\n",
      "took: 21.4 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 21.1 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 127.1 ms | avg took: 71.1 ms | fps: 14.1\n",
      "took: 20.8 ms | avg took: 71.1 ms | fps: 14.1\n",
      "took: 20.7 ms | avg took: 69.7 ms | fps: 14.3\n",
      "took: 106.3 ms | avg took: 70.6 ms | fps: 14.2\n",
      "took: 20.6 ms | avg took: 69.4 ms | fps: 14.4\n",
      "took: 118.1 ms | avg took: 70.4 ms | fps: 14.2\n",
      "took: 22.0 ms | avg took: 69.2 ms | fps: 14.5\n",
      "took: 149.5 ms | avg took: 70.5 ms | fps: 14.2\n",
      "took: 21.6 ms | avg took: 69.3 ms | fps: 14.4\n",
      "took: 142.0 ms | avg took: 69.4 ms | fps: 14.4\n",
      "took: 20.8 ms | avg took: 69.4 ms | fps: 14.4\n",
      "took: 30.6 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 54.3 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 50.3 ms | avg took: 70.1 ms | fps: 14.3\n",
      "took: 51.1 ms | avg took: 70.2 ms | fps: 14.2\n",
      "took: 140.0 ms | avg took: 70.1 ms | fps: 14.3\n",
      "took: 20.7 ms | avg took: 70.1 ms | fps: 14.3\n",
      "took: 20.5 ms | avg took: 69.0 ms | fps: 14.5\n",
      "took: 142.1 ms | avg took: 70.2 ms | fps: 14.2\n",
      "took: 21.0 ms | avg took: 69.9 ms | fps: 14.3\n",
      "took: 20.6 ms | avg took: 68.2 ms | fps: 14.7\n",
      "took: 21.0 ms | avg took: 68.2 ms | fps: 14.7\n",
      "took: 47.5 ms | avg took: 68.5 ms | fps: 14.6\n",
      "took: 49.6 ms | avg took: 67.8 ms | fps: 14.8\n",
      "took: 160.9 ms | avg took: 69.2 ms | fps: 14.5\n",
      "took: 21.4 ms | avg took: 68.1 ms | fps: 14.7\n",
      "took: 20.9 ms | avg took: 68.1 ms | fps: 14.7\n",
      "took: 21.2 ms | avg took: 66.8 ms | fps: 15.0\n",
      "took: 147.2 ms | avg took: 68.0 ms | fps: 14.7\n",
      "took: 20.9 ms | avg took: 68.0 ms | fps: 14.7\n",
      "took: 20.8 ms | avg took: 68.0 ms | fps: 14.7\n",
      "took: 139.6 ms | avg took: 68.1 ms | fps: 14.7\n",
      "took: 20.6 ms | avg took: 66.8 ms | fps: 15.0\n",
      "took: 124.5 ms | avg took: 67.9 ms | fps: 14.7\n",
      "took: 137.8 ms | avg took: 67.7 ms | fps: 14.8\n",
      "took: 141.8 ms | avg took: 68.9 ms | fps: 14.5\n",
      "took: 125.1 ms | avg took: 68.9 ms | fps: 14.5\n",
      "took: 21.6 ms | avg took: 67.9 ms | fps: 14.7\n",
      "took: 177.2 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 21.4 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 109.0 ms | avg took: 69.5 ms | fps: 14.4\n",
      "took: 22.1 ms | avg took: 68.5 ms | fps: 14.6\n",
      "took: 36.5 ms | avg took: 68.7 ms | fps: 14.6\n",
      "took: 48.8 ms | avg took: 69.0 ms | fps: 14.5\n",
      "took: 46.4 ms | avg took: 69.0 ms | fps: 14.5\n",
      "took: 162.6 ms | avg took: 69.1 ms | fps: 14.5\n",
      "took: 21.3 ms | avg took: 69.1 ms | fps: 14.5\n",
      "took: 20.5 ms | avg took: 69.1 ms | fps: 14.5\n",
      "took: 120.9 ms | avg took: 69.0 ms | fps: 14.5\n",
      "took: 21.0 ms | avg took: 68.0 ms | fps: 14.7\n",
      "took: 109.6 ms | avg took: 67.9 ms | fps: 14.7\n",
      "took: 118.1 ms | avg took: 68.9 ms | fps: 14.5\n",
      "took: 20.8 ms | avg took: 68.9 ms | fps: 14.5\n",
      "took: 20.5 ms | avg took: 68.0 ms | fps: 14.7\n",
      "took: 127.7 ms | avg took: 69.1 ms | fps: 14.5\n",
      "took: 20.9 ms | avg took: 69.1 ms | fps: 14.5\n",
      "took: 20.6 ms | avg took: 68.2 ms | fps: 14.7\n",
      "took: 139.9 ms | avg took: 68.6 ms | fps: 14.6\n",
      "took: 21.2 ms | avg took: 67.6 ms | fps: 14.8\n",
      "took: 21.5 ms | avg took: 67.7 ms | fps: 14.8\n",
      "took: 20.8 ms | avg took: 67.7 ms | fps: 14.8\n",
      "took: 31.5 ms | avg took: 67.8 ms | fps: 14.8\n",
      "took: 54.0 ms | avg took: 67.1 ms | fps: 14.9\n",
      "took: 176.5 ms | avg took: 68.6 ms | fps: 14.6\n",
      "took: 21.3 ms | avg took: 68.6 ms | fps: 14.6\n",
      "took: 132.1 ms | avg took: 68.7 ms | fps: 14.6\n",
      "took: 129.5 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 21.3 ms | avg took: 69.8 ms | fps: 14.3\n",
      "took: 136.0 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 21.3 ms | avg took: 70.0 ms | fps: 14.3\n",
      "took: 127.2 ms | avg took: 71.0 ms | fps: 14.1\n",
      "took: 135.5 ms | avg took: 71.1 ms | fps: 14.1\n",
      "took: 149.0 ms | avg took: 71.5 ms | fps: 14.0\n",
      "took: 21.4 ms | avg took: 70.5 ms | fps: 14.2\n",
      "took: 138.0 ms | avg took: 71.7 ms | fps: 13.9\n",
      "took: 132.7 ms | avg took: 71.8 ms | fps: 13.9\n",
      "took: 21.2 ms | avg took: 71.8 ms | fps: 13.9\n",
      "took: 20.5 ms | avg took: 71.8 ms | fps: 13.9\n"
     ]
    }
   ],
   "execution_count": 306
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making the model\n",
   "id": "3d767acd44343916"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T05:17:18.883173Z",
     "start_time": "2025-11-23T05:17:18.541822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# === LOAD YOUR MODEL HERE ===\n",
    "class HillClimbRacerV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 19 * 7, 128),  # input size matches 34x83 → (34-5)//2+1=15 → wait, recalc properly\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda')\n",
    "model = HillClimbRacerV1().to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# If you have a saved model, load it:\n",
    "# model.load_state_dict(torch.load('your_model.pth', map_location=device))\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Convert raw frame to model input tensor (1, 1, H, W)\"\"\"\n",
    "    # Example: crop, resize, grayscale, normalize\n",
    "    # ADJUST CROP/RESIZE TO YOUR GAME UI\n",
    "    cropped = frame[100:900, 200:2200]  # adjust based on your screen\n",
    "    resized = cv2.resize(cropped, (84, 84))\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    tensor = torch.from_numpy(gray).float() / 255.0\n",
    "    tensor = tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, 84, 84)\n",
    "    return tensor.to(device)\n",
    "\n",
    "\n",
    "def get_action_from_model(frame):\n",
    "    tensor = preprocess_frame(frame)\n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor)\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "    actions = [\"accel\", \"brake\", \"none\"]\n",
    "    return actions[pred]"
   ],
   "id": "dbcd9c329b4a120f",
   "outputs": [],
   "execution_count": 301
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
